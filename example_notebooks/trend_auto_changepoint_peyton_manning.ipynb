{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ourownstory/neural_prophet/blob/master/example_notebooks/trend_peyton_manning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic trend changepoint selection\n",
    "This is a continuation of the example notebook `trend_peyton_manning`, focusing on automatic changepoint selection.\n",
    "\n",
    "We learned in that notebook how we can increase the flexibility of the trend, at the danger of overfitting.\n",
    "\n",
    "Now, we will learn how to use regularization to avoid overfitting while maintaining high flexibility, resuting in something that could be described as 'automatic trend changepoint selection'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install git+https://github.com/ourownstory/neural_prophet.git # may take a while\n",
    "    #!pip install neuralprophet # much faster, but may not have the latest upgrades/bugfixes\n",
    "    data_location = \"https://raw.githubusercontent.com/ourownstory/neural_prophet/master/\"\n",
    "else:\n",
    "    data_location = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "# set_log_level(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_location + \"example_data/wp_log_peyton_manning.csv\")\n",
    "# df.head(3)\n",
    "lr = None\n",
    "epochs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitted Trend\n",
    "As this dataset has some strong seasonality, we would usually fit it with seasonality enabled.\n",
    "For demonstration purposes, we manually disable all seasonalities here to show how Trend can overfit to seasonal patterns, and how to avoid this with regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ef5ac28b68421f886140d0e69543f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils_torch.lr_range_test) - lr-range-test results: steep: 8.37E-02, min: 2.02E+01\n",
      "INFO - (NP.utils_torch.lr_range_test) - learning rate range test selected lr: 3.24E+00\n",
      "Epoch[91/91]: 100%|██████████| 91/91 [00:09<00:00, 10.08it/s, SmoothL1Loss=0.00809, MAE=0.4, MSE=0.327, RegLoss=0]  \n"
     ]
    }
   ],
   "source": [
    "m = NeuralProphet(\n",
    "    learning_rate=lr,\n",
    "    epochs=epochs,\n",
    "    n_changepoints=50,\n",
    "    trend_reg=0,\n",
    "    changepoints_range=0.90,    \n",
    "    daily_seasonality=False,\n",
    "    weekly_seasonality=False,\n",
    "    yearly_seasonality=False,\n",
    ")\n",
    "metrics = m.fit(df, freq=\"D\")\n",
    "future = m.make_future_dataframe(df, n_historic_predictions=len(df))\n",
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig1 = m.plot(forecast)\n",
    "# fig2 = m.plot_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regularized clearly overfits to the annual seasonal pattern - we can't really call this a 'trend'. Let's try addressing this by adding moderate regularization:\n",
    "\n",
    "## Regularized Trend:\n",
    "By adding regularization, we can achieve an automatic selection of the most relevant changepoints and draw the rate changes of other points close to zero. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31adbfaeab0f4ee4aecc8a16a6830285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils_torch.lr_range_test) - lr-range-test results: steep: 4.99E-03, min: 1.76E+00\n",
      "INFO - (NP.utils_torch.lr_range_test) - learning rate range test selected lr: 2.49E-01\n",
      "Epoch[91/91]: 100%|██████████| 91/91 [00:08<00:00, 10.60it/s, SmoothL1Loss=0.0161, MAE=0.62, MSE=0.651, RegLoss=0.0831]  \n"
     ]
    }
   ],
   "source": [
    "m = NeuralProphet(\n",
    "    learning_rate=lr,\n",
    "    epochs=epochs,\n",
    "    n_changepoints=50,\n",
    "    trend_reg=1,\n",
    "    changepoints_range=0.90,    \n",
    "    daily_seasonality=False,\n",
    "    weekly_seasonality=False,\n",
    "    yearly_seasonality=False,\n",
    ")\n",
    "metrics = m.fit(df, freq=\"D\")\n",
    "future = m.make_future_dataframe(df, n_historic_predictions=len(df))\n",
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig1 = m.plot(forecast)\n",
    "# fig2 = m.plot_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now the model selects fewer trend changepoints, drawing the rest closer to zero. But there is still room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Trend Flexibility\n",
    "We can adjust the regularization strength to get more or less points with a non-zero rate change.\n",
    "\n",
    "Note: for too high regularization strengths, the model fitting process becomes unstable. If so, take manual control of learning rate and potentially more hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ecd1a6990f4184b2a76be92f6a6871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils_torch.lr_range_test) - lr-range-test results: steep: 7.89E-03, min: 1.90E+00\n",
      "INFO - (NP.utils_torch.lr_range_test) - learning rate range test selected lr: 3.06E-01\n",
      "Epoch[91/91]: 100%|██████████| 91/91 [00:08<00:00, 10.56it/s, SmoothL1Loss=0.0176, MAE=0.652, MSE=0.713, RegLoss=3.37e-5] \n"
     ]
    }
   ],
   "source": [
    "m = NeuralProphet(\n",
    "    learning_rate=lr,\n",
    "    epochs=epochs,\n",
    "    n_changepoints=50,\n",
    "    trend_reg=5,\n",
    "    changepoints_range=0.90,   \n",
    "    daily_seasonality=False,\n",
    "    weekly_seasonality=False,\n",
    "    yearly_seasonality=False,\n",
    ")\n",
    "metrics = m.fit(df, freq=\"D\")\n",
    "future = m.make_future_dataframe(df, n_historic_predictions=len(df))\n",
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig1 = m.plot(forecast)\n",
    "# fig2 = m.plot_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v-np-dev",
   "language": "python",
   "name": "v-np-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
