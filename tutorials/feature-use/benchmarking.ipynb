{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca8c35e-d7c4-4eed-a69b-324a3ffdbea8",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ourownstory/neural_prophet/blob/master/tutorials/feature-use/benchmarking.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2af163-c378-4e01-8d5b-3def6194c29e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running benchmarking experiments\n",
    "Note: The Benchmarking Framework does currently not properly support auto-regression or lagged covariates with multiple step ahead forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80400b6d-ca57-47ba-9dc5-0da3885ab6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.benchmark.<module>) - Benchmarking Framework is not covered by tests. Please report any bugs you find.\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install git+https://github.com/ourownstory/neural_prophet.git # may take a while\n",
    "    #!pip install neuralprophet # much faster, but may not have the latest upgrades/bugfixes\n",
    "    \n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "from neuralprophet.benchmark import Dataset, NeuralProphetModel, ProphetModel, SimpleExperiment, CrossValidationExperiment\n",
    "from neuralprophet.benchmark import SimpleBenchmark, CrossValidationBenchmark\n",
    "set_log_level(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e79793-8ebb-4d06-b021-82b49d107653",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930697ee-179c-4821-bbb7-c2f5e4588093",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = \"https://raw.githubusercontent.com/ourownstory/neuralprophet-data/main/datasets/\"\n",
    "\n",
    "air_passengers_df = pd.read_csv(data_location + 'air_passengers.csv')\n",
    "peyton_manning_df = pd.read_csv(data_location + 'wp_log_peyton_manning.csv')\n",
    "# retail_sales_df = pd.read_csv(data_location + 'retail_sales.csv')\n",
    "# yosemite_temps_df = pd.read_csv(data_location +  'yosemite_temps.csv')\n",
    "# ercot_load_df = pd.read_csv(data_location +  'ERCOT_load_2004_2021Sept.csv')[['ds', 'y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0b0c0-eeaa-4a1f-9251-84d41da1deae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Configure Datasets and Model Parameters\n",
    "First, we define the datasets that we would like to benchmerk on.\n",
    "Next, we define the models that we want to evaluate and set their hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac375354-7755-48a7-b628-d322c0232f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = [\n",
    "    Dataset(df = air_passengers_df, name = \"air_passengers\", freq = \"MS\"),\n",
    "    Dataset(df = peyton_manning_df, name = \"peyton_manning\", freq = \"D\"),\n",
    "    # Dataset(df = retail_sales_df, name = \"retail_sales\", freq = \"D\"),\n",
    "    # Dataset(df = yosemite_temps_df, name = \"yosemite_temps\", freq = \"5min\"),\n",
    "    # Dataset(df = ercot_load_df, name = \"ercot_load\", freq = \"H\"),\n",
    "]\n",
    "model_classes_and_params = [\n",
    "    (NeuralProphetModel, {}),\n",
    "    (NeuralProphetModel, {\"seasonality_mode\": \"multiplicative\", \"learning_rate\": 0.1}),\n",
    "    (ProphetModel, {})\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e64a14-ab54-43b8-8115-1c6c02996e7c",
   "metadata": {},
   "source": [
    "Note: As all the classes used in the Benchmark framework are dataclasses, \n",
    "they have a print function, allowing us to peek into them if we like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5ac40e-8ce3-427f-be00-f2590dacc3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(neuralprophet.benchmark.NeuralProphetModel, {}),\n",
       " (neuralprophet.benchmark.NeuralProphetModel,\n",
       "  {'seasonality_mode': 'multiplicative', 'learning_rate': 0.1}),\n",
       " (neuralprophet.benchmark.ProphetModel, {})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classes_and_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b924887-1728-4506-9275-92ec4be61033",
   "metadata": {},
   "source": [
    "## 1. SimpleBenchmark\n",
    "Setting up a series of Train Test Experiments is quick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e909a2-cbc5-4703-a1e6-8963921b6364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5609c3431a9045a59051744731d0aaa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                        \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Requires prophet to be installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36821/4241874925.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest_percentage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresults_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/github/neural_prophet/neuralprophet/benchmark.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;31m# todo: parallelize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mres_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m             \u001b[0mdf_metrics_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_metrics_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mdf_metrics_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_metrics_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/neural_prophet/neuralprophet/benchmark.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mvalid_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_percentage\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         )\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mresult_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/neural_prophet/neuralprophet/benchmark.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, model_name, model_class)\u001b[0m\n",
      "\u001b[0;32m~/github/neural_prophet/neuralprophet/benchmark.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_prophet_installed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Requires prophet to be installed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Requires prophet to be installed"
     ]
    }
   ],
   "source": [
    "benchmark = SimpleBenchmark(\n",
    "    model_classes_and_params=model_classes_and_params, # iterate over this list of tuples\n",
    "    datasets=dataset_list, # iterate over this list\n",
    "    metrics=[\"MAE\", \"MSE\", \"MASE\", \"RMSE\"],\n",
    "    test_percentage=25,\n",
    ")\n",
    "results_train, results_val = benchmark.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a689e-47f5-45cb-9b2f-18196d149348",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7977f0ce-d0c6-4d0c-9edc-a62862d1ea1e",
   "metadata": {},
   "source": [
    "## 2. CrossValidationBenchmark\n",
    "Setting up a series of crossvalidated experiments is just as simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a78380-0e77-4ecf-a356-4c89cdf52625",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_cv = CrossValidationBenchmark(\n",
    "    model_classes_and_params=model_classes_and_params, # iterate over this list of tuples\n",
    "    datasets=dataset_list, # iterate over this list\n",
    "    metrics=[\"MAE\", \"MSE\"],\n",
    "    test_percentage=10,\n",
    "    num_folds=3,\n",
    "    fold_overlap_pct=0,\n",
    ")\n",
    "results_summary, results_train, results_val = benchmark_cv.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ca0381-7469-427f-b924-1269ff9f4c50",
   "metadata": {},
   "source": [
    "We now also get a summary DataFrame showing the metrics' mean and standard deviation over all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653ed48e-221d-48b2-81af-f1a172fe2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12697c82-16f0-4807-8ac5-66aa730fa0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_passengers = results_summary[results_summary['data'] == 'air_passengers']\n",
    "plt = air_passengers.plot(x='params', y=['val_MAE', 'val_MAE_std'], kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32fd49-55c6-4cd4-9082-3ee073cc741e",
   "metadata": {},
   "source": [
    "The metrics for each fold are also recoreded individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf240d-a6a8-4433-b12f-3fa3921d8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddffda4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "np-dev",
   "language": "python",
   "name": "np-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
